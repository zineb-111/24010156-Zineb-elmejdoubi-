---

# üìò GRAND GUIDE : ANATOMIE D'UN PROJET DATA SCIENCE

Ce document d√©cortique chaque √©tape du cycle de vie d'un projet de Machine Learning. Il est con√ßu pour passer du niveau "d√©butant qui copie du code" au niveau "ing√©nieur qui comprend les m√©canismes internes".

---

## 1. Le Contexte M√©tier et la Mission

### Le Probl√®me (Business Case)
Dans le domaine m√©dical, la fatigue des radiologues ou la complexit√© des images peuvent mener √† des erreurs de diagnostic.
*   **Objectif :** Cr√©er un "Assistant IA" pour le second avis m√©dical.
*   **L'Enjeu critique :** La matrice des co√ªts d'erreur est asym√©trique.
    *   Dire √† un patient sain qu'il est malade (Faux Positif) g√©n√®re du stress et des co√ªts de biopsie.
    *   Dire √† un patient malade qu'il est sain (Faux N√©gatif) peut entra√Æner la mort par retard de traitement. **L'IA doit donc prioriser la sensibilit√© (Recall).**

### Les Donn√©es (L'Input)
Nous utilisons le *Breast Cancer Wisconsin Dataset*.
*   **X (Features) :** 30 colonnes. Ce ne sont pas des pixels bruts, mais des caract√©ristiques math√©matiques extraites d'images de cellules (Rayon moyen, √âcart-type de la texture, "Pire" concavit√©, etc.).
*   **y (Target) :** Binaire. `0` = Malin, `1` = B√©nin.

---

## 2. Le Code Python (Laboratoire)

Ce script est votre paillasse de laboratoire. Il contient toutes les manipulations n√©cessaires.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Configuration
sns.set_theme(style="whitegrid")
import warnings
warnings.filterwarnings('ignore')

# --- PHASE 1 : ACQUISITION & SIMULATION ---
data = load_breast_cancer()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

# Simulation de la r√©alit√© (Donn√©es sales)
np.random.seed(42)
df_dirty = df.copy()
# On corrompt 5% des donn√©es avec des NaN
for col in df.columns[:-1]:
    df_dirty.loc[df_dirty.sample(frac=0.05).index, col] = np.nan

# --- PHASE 2 : DATA WRANGLING (NETTOYAGE) ---
X = df_dirty.drop('target', axis=1)
y = df_dirty['target']

# Strat√©gie d'imputation
imputer = SimpleImputer(strategy='mean')
# fit = apprend la moyenne, transform = bouche les trous
X_imputed = imputer.fit_transform(X)
X_clean = pd.DataFrame(X_imputed, columns=X.columns)

# --- PHASE 3 : ANALYSE EXPLORATOIRE (EDA) ---
print("--- Statistiques Descriptives ---")
print(X_clean.iloc[:, :5].describe())

# --- PHASE 4 : PROTOCOLE EXP√âRIMENTAL (SPLIT) ---
X_train, X_test, y_train, y_test = train_test_split(
    X_clean, y, test_size=0.2, random_state=42
)

# --- PHASE 5 : INTELLIGENCE ARTIFICIELLE (RANDOM FOREST) ---
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# --- PHASE 6 : AUDIT DE PERFORMANCE ---
y_pred = model.predict(X_test)

print(f"\n--- Accuracy Globale : {accuracy_score(y_test, y_pred)*100:.2f}% ---")
print("\n--- Rapport D√©taill√© ---")
print(classification_report(y_test, y_pred, target_names=data.target_names))

# Visualisation des erreurs
plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title('Matrice de Confusion : R√©alit√© vs IA')
plt.ylabel('Vraie Classe')
plt.xlabel('Classe Pr√©dite')
plt.show()
```

---

## 3. Analyse Approfondie : Nettoyage (Data Wrangling)

### Le Probl√®me Math√©matique du "Vide"
Les algorithmes d'alg√®bre lin√©aire (qui calculent des distances entre points) ne peuvent pas g√©rer la valeur `NaN` (Not a Number). Une seule valeur manquante peut faire planter tout le calcul matriciel.

### La M√©canique de l'Imputation
Nous utilisons `SimpleImputer(strategy='mean')`.
1.  **L'Apprentissage (`fit`) :** L'imputer scanne la colonne "Rayon" de tous les patients disponibles. Il calcule $\mu$ (la moyenne), disons 14.12mm. Il stocke cette valeur en m√©moire.
2.  **La Transformation (`transform`) :** Il repasse sur les donn√©es. S'il voit un trou, il injecte 14.12mm.

### üí° Le Coin de l'Expert (Data Leakage)
*Attention :* Dans ce script p√©dagogique, nous avons nettoy√© *avant* de s√©parer (Train/Test). Dans un syst√®me industriel ultra-rigoureux, c'est une erreur subtile appel√©e **Data Leakage** (Fuite de donn√©es).
*   *Pourquoi ?* En calculant la moyenne sur tout le monde, la moyenne inclut des infos du futur Test Set.
*   *La bonne pratique absolue :* S√©parer d'abord, calculer la moyenne sur le Train, et utiliser cette moyenne "Train" pour boucher les trous du Test.

---

## 4. Analyse Approfondie : Exploration (EDA)

C'est l'√©tape de "Profilage".

### D√©crypter `.describe()`
*   **Mean (Moyenne) vs 50% (M√©diane) :** Comparez ces deux lignes. Si la Moyenne est beaucoup plus haute que la M√©diane, cela indique une **distribution asym√©trique** (skewed) tir√©e vers le haut par des valeurs extr√™mes.
*   **Std (√âcart-type) :** Mesure la "largeur" de la cloche de distribution. Une variable avec un std proche de 0 est inutile (c'est une constante).

### La Multicollin√©arit√© (Le probl√®me de la redondance)
En regardant une Heatmap, on verrait que `Radius` (Rayon), `Perimeter` (P√©rim√®tre) et `Area` (Aire) sont corr√©l√©s √† >99%.
*   *G√©om√©triquement :* C'est logique ($P = 2\pi R$).
*   *Impact ML :* Pour un Random Forest, ce n'est pas grave. Mais pour une R√©gression Logistique, cela rendrait le mod√®le instable car il ne saurait pas √† quelle variable attribuer le "poids" de la d√©cision.

---

## 5. Analyse Approfondie : M√©thodologie (Split)

### Le Concept : La Garantie de G√©n√©ralisation
Le but du Machine Learning n'est pas de *m√©moriser* le pass√©, mais de *g√©n√©raliser* vers le futur.

### Les Param√®tres sous le capot
`train_test_split(test_size=0.2, random_state=42)`
1.  **Le Ratio 80/20 (Le principe de Pareto) :** On garde la majorit√© des donn√©es pour que le mod√®le puisse capturer la complexit√© des motifs (Train). On en garde juste assez (Test) pour que la note finale soit statistiquement significative.
2.  **La Reproductibilit√© (`random_state`) :** En informatique, le "vrai" hasard n'existe pas. C'est du pseudo-al√©atoire. Fixer la graine √† 42 assure que si vous envoyez votre code √† un coll√®gue au Japon, il obtiendra *exactement* les m√™mes patients dans son jeu de test. C'est crucial pour la validation scientifique.

---

## 6. FOCUS TH√âORIQUE : L'Algorithme Random Forest üå≤

Pourquoi est-ce l'algorithme "couteau suisse" pr√©f√©r√© des Data Scientists ?

### A. La Faiblesse de l'Individu (Arbre de D√©cision)
Un Arbre de D√©cision unique pose des questions en cascade.
*   *Probl√®me :* Il est **obsessif**. Si, dans vos donn√©es d'entra√Ænement, il y a une aberration (un patient sain avec un rayon √©norme), l'arbre va cr√©er une r√®gle sp√©cifique pour lui. Il apprend le bruit. On dit qu'il a une **haute variance**.

### B. La Force du Groupe (Bagging)
Random Forest signifie "For√™t Al√©atoire". Il cr√©e 100 arbres (ou plus). Pour qu'ils ne soient pas tous identiques, on introduit du chaos contr√¥l√© √† deux niveaux :

1.  **Le Bootstrapping (Diversit√© des √âleves) :**
    *   Chaque arbre ne voit pas tout le monde. L'Arbre #1 s'entra√Æne sur les patients A, B, C. L'Arbre #2 sur A, C, D.
    *   *Cons√©quence :* Chaque arbre d√©veloppe une "opinion" bas√©e sur une exp√©rience diff√©rente.

2.  **Feature Randomness (Diversit√© des Questions) :**
    *   C'est la magie du Random Forest. √Ä chaque fois qu'un arbre veut poser une question pour s√©parer les malades des sains, il n'a acc√®s qu'√† un sous-ensemble al√©atoire de colonnes (ex: $\sqrt{nb\_colonnes}$).
    *   *Cons√©quence :* Cela force les arbres √† regarder des variables moins √©videntes (comme la texture ou la sym√©trie) au lieu de se focaliser uniquement sur le rayon.

### C. Le Consensus (Vote)
Lorsqu'un nouveau patient arrive :
*   Les 100 arbres font leur diagnostic individuellement.
*   On fait un vote √† la majorit√©.
*   Les erreurs individuelles des arbres (bruit) s'annulent math√©matiquement, ne laissant que la tendance lourde (le signal).

---

## 7. Analyse Approfondie : √âvaluation (L'Heure de V√©rit√©)

Comment lire les r√©sultats comme un pro ?

### A. La Matrice de Confusion (Quadrants)
*   **Vrais Positifs (TP) :** *Pr√©dit Cancer | R√©el Cancer.* (Succ√®s).
*   **Vrais N√©gatifs (TN) :** *Pr√©dit Sain | R√©el Sain.* (Succ√®s).
*   **Faux Positifs (FP - Erreur de Type I) :** *Pr√©dit Cancer | R√©el Sain.*
    *   *Impact :* Stress psychologique, co√ªt.
*   **Faux N√©gatifs (FN - Erreur de Type II) :** *Pr√©dit Sain | R√©el Cancer.*
    *   *Impact :* **Danger de mort.** C'est la m√©trique √† surveiller absolument ici.

### B. Les M√©triques Avanc√©es
L'Accuracy (Pr√©cision globale) est dangereuse si les classes sont d√©s√©quilibr√©es (ex: 99% de sains).
On regarde donc :

1.  **La Pr√©cision (Precision) :** "Qualit√© de l'alarme".
    $$TP / (TP + FP)$$
    *   Si elle est basse, l'IA crie "Au loup !" trop souvent pour rien.

2.  **Le Rappel (Recall / Sensibilit√©) :** "Puissance du filet".
    $$TP / (TP + FN)$$
    *   Si elle est basse (ex: 0.60), l'IA laisse passer 40% des cancers. **Inacceptable en m√©decine.**
    *   *Objectif pro :* Maximiser le Recall, quitte √† accepter un peu plus de Faux Positifs.

3.  **F1-Score :** La moyenne harmonique des deux pr√©c√©dents. C'est la note unique la plus honn√™te pour comparer deux mod√®les.

### Conclusion du Projet
Ce rapport montre que la Data Science ne s'arr√™te pas √† `model.fit()`. C'est une cha√Æne de d√©cisions logiques o√π la compr√©hension du m√©tier (m√©decine) dicte le choix des algorithmes (Random Forest pour la robustesse) et des m√©triques (Recall pour la s√©curit√©).
